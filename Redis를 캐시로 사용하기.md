Redis를 캐시로 잘 사용하기 _ nhn
- https://www.youtube.com/watch?v=92NizoBL4uA

1. 캐시를 왜 사용하는가?
```
원본 데이터에 접근하는 속도보다 빠르게 데이터에 액세스하기 위한 임시 저장소

즉 
원본 접근보다 빠르며
수정이 빈번하지 않으며
데이터 재사용이 빈번한 경우 효율적 
```
2. redis as a cache
```
단순한 key-value구조 -> key값으로 바로 조회 가능
in-memory 데이터 저장소 -> 모든 데이터를 메모리에 올려두기에 빠른 접근 가능 / disk에 저장한다고하면 찾는데 오래걸리겠죠?

이로인해 빠른속도로
평균 작업속도가 1 ms미만으로
초당 수백만건 가능 
```

3. 캐싱전략

### 1. 읽기 전략 / look aside
```
1. 캐시에서 먼저 데이터 존재하는지 확인
2. 없으면 db접근 후 캐시에 업데이트

장점 : 만약 레디스가 죽어도 디비 접근으로 서비스 정상 운영가능
단점 : 레디스와 연결된 커넥션이 많은 상황에서 레디스가 죽으면 커넥션이 모두 디비로 향하게되고 디비 과부하 발생 가능

추가로 캐시를 처음 올릴때 아무것도 하지 않으면 처음에는 캐시 미스가 발생하여 성능 저하가 일어날 수 있다
따라서 미리 데이터를 밀어넣는 작업이 필요할수도있다
```

### 2-1. 쓰기 전략 / write around
```
모든 정보는 데이터베이스에만 write한다
캐시에는 miss가 발생할때만 정보를 write한다

장점 : 캐시에 write가 적으니 부하가 적다
단점 : ⭐️ 캐시 미스 혹은 디비에 데이터는 변경되었지만 아직 캐시에 반영이 안된경우
디비에 저장된 데이터와 캐시에 저장된 데이터가 다를 수 있다.
```
### 2-2. 쓰기 전략 / write through
```
모든 정보는 디비에 저장하면서 캐시에도 저장한다

이러면 당연히 캐시는 항상 최신 정보를 갖을 수 있지만
저장마다 캐시, 디비 두 단계를 거쳐야한다 -> 느리다

또한 만약 저장하는 모든 데이터가 재사용되는 데이터가 아닐때 
캐시에 저장할 필요가 없는 데이터를 저장하게되고 쓸모없이 용량을 잡아먹는다

따라서 write through 방식을 사용할 땐 캐시에 데이터를 얼마나 저장할지 expire time을 잘 지정해줘야한다. 
```

### 나는 어떤 전략이 좋다고 생각하는가?
```
1,2 혼용이 필요하다고 생각

기본적으로 데이터 저장은 디비에만 저장
- 새로운 데이터에 대해서는 캐시 miss 발생시 캐시에 업데이트

변경 및 삭제가 발생한 데이터는 그때그때 바로 캐시에도 업데이트
- 캐시와 디비 데이터 정합성을 맞추고자
```

### 장애를 막기위한 기본 설정
1. stop-writes-on-bgsave-error => no
```
rdb 파일 저장 실패시 redis로 모든 write불가능
기본 yes
```
2. maxmemory-policy = allkeys-lru
```
redis를 캐시로 사용할땐 expire-time 설정을 해줘야한다
그런데 추가로 메모리가 다 찼을때 어떻게 동작할지 설정도 필요하다

기본은 no-eviction으로 기존 데이터를 삭제하지 않고 그로인해 메모리가 다 차면 사용 불가능

valotile-lru : expire time이 설정된 키값을 대상으로만 lru로 지운다 -> 실수로 expire time 설정이 안되어있으면 계속 쌓인다
allkeys-lru : 모든 키를 대상으로 lru로 지운다 ⭐️

```
3. Cache Stampede / expire-time을 너무 작게 설정하는경우
- https://meetup.toast.com/posts/251
```
여러개의 서버가 레디스와 통신하는 상황에서 expire-time이 너무 짧다고 생각해보자
그럼 그 만큼 자주 여러 서버가 디비로 데이터를 읽으러가고 또 해당 내용을 캐시에 다시 쓰는 행위가 빈번할것
만약 여러개의 서버가 같은 키를 바라보고있다가 키가 만료되면?
동시에 여러 서버가 디비에 접근해서 읽는 / duplicate read
이 후 동시에 여러 서버가 레디스에 데이터 업데이트하는 / duplicate write가 발생
-> 엄청난 성능 이슈

참고
이 현상을 해결하기 위해 PER(Probablistic Early Recomputation) 알고리즘을 도입할 수 있습니다.
이 알고리즘은 키의 TTL이 실제로 만료되기 전에 일정 확률로 캐시를 갱신하는 방법입니다. 
데이터베이스에서 키가 완전히 만료되기 전에 데이터를 먼저 읽어오게 함으로써 Cache Stampede 현상을 막을 수 있습니다.
```


